- info: {}
  key: pmlr:v180:deleu22a
  paper:
    abstract: In Bayesian structure learning, we are interested in inferring a distribution
      over the directed acyclic graph (DAG) structure of Bayesian networks, from data.
      Defining such a distribution is very challenging, due to the combinatorially
      large sample space, and approximations based on MCMC are often required. Recently,
      a novel class of probabilistic models, called Generative Flow Networks (GFlowNets),
      have been introduced as a general framework for generative modeling of discrete
      and composite objects, such as graphs. In this work, we propose to use a GFlowNet
      as an alternative to MCMC for approximating the posterior distribution over
      the structure of Bayesian networks, given a dataset of observations. Generating
      a sample DAG from this approximate distribution is viewed as a sequential decision
      problem, where the graph is constructed one edge at a time, based on learned
      transition probabilities. Through evaluation on both simulated and real data,
      we show that our approach, called DAG-GFlowNet, provides an accurate approximation
      of the posterior over DAGs, and it compares favorably against other methods
      based on MCMC or variational inference.
    authors:
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Tristan Deleu
      display_name: Tristan Deleu
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Ant贸nio G贸is
      display_name: Ant贸nio G贸is
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Chris Emezue
      display_name: Chris Emezue
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Mansi Rankawat
      display_name: Mansi Rankawat
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Simon Lacoste-Julien
      display_name: Simon Lacoste-Julien
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Stefan Bauer
      display_name: Stefan Bauer
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    flags: []
    links:
    - link: 180/deleu22a
      type: mlr
    - link: https://proceedings.mlr.press/v180/deleu22a/deleu22a.pdf
      type: pdf
    releases:
    - pages: 518-528
      status: published
      venue:
        aliases: []
        date: '2022-08-17'
        date_precision: 3
        links: []
        name: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
          Intelligence
        open: false
        peer_reviewed: true
        publisher: PMLR
        series: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
          Intelligence
        type: unknown
        volume: '180'
    title: Bayesian structure learning with generative flow networks
    topics: []
  score: 0.0
- info: {}
  key: pmlr:v180:erraqabi22a
  paper:
    abstract: In reinforcement learning, the graph Laplacian has proved to be a valuable
      tool in the task-agnostic setting, with applications ranging from skill discovery
      to reward shaping. Recently, learning the Laplacian representation has been
      framed as the optimization of a temporally-contrastive objective to overcome
      its computational limitations in large (or continuous) state spaces. However,
      this approach requires uniform access to all states in the state space, overlooking
      the exploration problem that emerges during the representation learning process.
      In this work, we propose an alternative method that is able to recover, in a
      non-uniform-prior setting, the expressiveness and the desired properties of
      the Laplacian representation. We do so by combining the representation learning
      with a skill-based covering policy, which provides a better training distribution
      to extend and refine the representation. We also show that a simple augmentation
      of the representation objective with the learned temporal abstractions improves
      dynamics-awareness and helps exploration. We find that our method succeeds as
      an alternative to the Laplacian in the non-uniform setting and scales to challenging
      continuous control environments. Finally, even if our method is not optimized
      for skill discovery, the learned skills can successfully solve difficult continuous
      navigation tasks with sparse rewards, where standard skill discovery approaches
      are no so effective.
    authors:
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Akram Erraqabi
      display_name: Akram Erraqabi
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Marlos C. Machado
      display_name: Marlos C. Machado
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Mingde Zhao
      display_name: Mingde Zhao
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Sainbayar Sukhbaatar
      display_name: Sainbayar Sukhbaatar
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Alessandro Lazaric
      display_name: Alessandro Lazaric
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Denoyer Ludovic
      display_name: Denoyer Ludovic
    - affiliations: []
      author:
        aliases: []
        links: []
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    flags: []
    links:
    - link: 180/erraqabi22a
      type: mlr
    - link: https://proceedings.mlr.press/v180/erraqabi22a/erraqabi22a.pdf
      type: pdf
    releases:
    - pages: 641-651
      status: published
      venue:
        aliases: []
        date: '2022-08-17'
        date_precision: 3
        links: []
        name: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
          Intelligence
        open: false
        peer_reviewed: true
        publisher: PMLR
        series: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
          Intelligence
        type: unknown
        volume: '180'
    title: 'Temporal abstractions-augmented temporally contrastive learning: An alternative
      to the Laplacian in RL'
    topics: []
  score: 0.0
