"[\n  {\n    \"abstract\": \"Autoregressive large language models (LLMs) compress\
  \ knowledge from their training data through next-token conditional distributions.\
  \ This limits tractable querying of this knowledge to start-to-end autoregressive\
  \ sampling. However, many tasks of interest---including sequence continuation, infilling,\
  \ and other forms of constrained generation---involve sampling from intractable\
  \ posterior distributions. We address this limitation by using amortized Bayesian\
  \ inference to sample from these intractable posteriors. Such amortization is algorithmically\
  \ achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms:\
  \ generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching\
  \ paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood\
  \ training and reward-maximizing policy optimization. As an important application,\
  \ we interpret chain-of-thought reasoning as a latent variable modeling problem\
  \ and demonstrate that our approach enables data-efficient adaptation of LLMs to\
  \ tasks that require multi-step rationalization and tool use.\",\n    \"authors\"\
  : [\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila / Universit\\\
  u00e9 de Montr\\u00e9al\"\n          }\n        ],\n        \"author\": {\n    \
  \      \"aliases\": [],\n          \"links\": [\n            {\n              \"\
  link\": \"http://iclr.cc/api/miniconf/users/6671?format=json\",\n              \"\
  type\": \"profile\"\n            }\n          ],\n          \"name\": \"Nikolay\
  \ Malkin\"\n        },\n        \"display_name\": \"Nikolay Malkin\"\n      },\n\
  \      {\n        \"affiliations\": [\n          {\n            \"aliases\": [],\n\
  \            \"category\": \"unknown\",\n            \"name\": \"Mila\"\n      \
  \    }\n        ],\n        \"author\": {\n          \"aliases\": [],\n        \
  \  \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/32612?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Eric Elmoznino\"\n        },\n        \"display_name\": \"Eric Elmoznino\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila\"\n\
  \          }\n        ],\n        \"author\": {\n          \"aliases\": [],\n  \
  \        \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/49551?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Edward Hu\"\n        },\n        \"display_name\": \"Edward Hu\"\n   \
  \   },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila, Quebec\
  \ AI institute\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/43856?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Guillaume Lajoie\"\n        },\n        \"display_name\": \"Guillaume\
  \ Lajoie\"\n      },\n      {\n        \"affiliations\": [\n          {\n      \
  \      \"aliases\": [],\n            \"category\": \"unknown\",\n            \"\
  name\": \"Mila, Universit\\u00e9 de Montr\\u00e9al\"\n          }\n        ],\n\
  \        \"author\": {\n          \"aliases\": [],\n          \"links\": [\n   \
  \         {\n              \"link\": \"http://iclr.cc/api/miniconf/users/19397?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Moksh Jain\"\n        },\n        \"display_name\": \"Moksh Jain\"\n \
  \     },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila, University\
  \ of Montreal\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/6784?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Yoshua Bengio\"\n        },\n        \"display_name\": \"Yoshua Bengio\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"University\
  \ of Oxford\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/86716?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Younesse Kaddar\"\n        },\n        \"display_name\": \"Younesse Kaddar\"\
  \n      }\n    ],\n    \"flags\": [],\n    \"links\": [\n      {\n        \"link\"\
  : \"2024-Oral--1391-05763559\",\n        \"type\": \"openreview\"\n      },\n  \
  \    {\n        \"link\": \"Ouj6p4ca60\",\n        \"type\": \"openreview\"\n  \
  \    },\n      {\n        \"link\": \"https://iclr.cc/media/iclr-2024/Slides/18725.pdf\"\
  ,\n        \"type\": \"slides\"\n      },\n      {\n        \"link\": \"https://iclr.cc/virtual/2024/poster/18725\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"https://openreview.net/forum?id=Ouj6p4ca60\"\
  ,\n        \"type\": \"abstract\"\n      }\n    ],\n    \"releases\": [\n      {\n\
  \        \"pages\": null,\n        \"status\": \"Accept (oral)\",\n        \"venue\"\
  : {\n          \"aliases\": [],\n          \"date\": \"2024-05-07\",\n         \
  \ \"date_precision\": 3,\n          \"links\": [],\n          \"name\": \"ICLR\"\
  ,\n          \"open\": true,\n          \"peer_reviewed\": true,\n          \"publisher\"\
  : null,\n          \"series\": \"ICLR\",\n          \"type\": \"conference\",\n\
  \          \"volume\": null\n        }\n      }\n    ],\n    \"title\": \"Amortizing\
  \ intractable inference in large language models\",\n    \"topics\": [\n      {\n\
  \        \"name\": \"Deep Learning->Large Language Models\"\n      }\n    ]\n  },\n\
  \  {\n    \"abstract\": \"Misclassification detection is an important problem in\
  \ machine learning, as it allows for the identification of instances where the model's\
  \ predictions are unreliable. However, conventional uncertainty measures such as\
  \ Shannon entropy do not provide an effective way to infer the real uncertainty\
  \ associated with the model's predictions. In this paper, we introduce a novel data-driven\
  \ measure of uncertainty relative to an observer for misclassification detection.\
  \ By learning patterns in the distribution of soft-predictions, our uncertainty\
  \ measure can identify misclassified samples based on the predicted class probabilities.\
  \  Interestingly, according to the proposed measure, soft-predictions corresponding\
  \ to misclassified instances can carry a large amount of uncertainty, even though\
  \ they may have low Shannon entropy. We demonstrate empirical improvements over\
  \ multiple image classification tasks, outperforming state-of-the-art misclassification\
  \ detection methods.\",\n    \"authors\": [\n      {\n        \"affiliations\":\
  \ [\n          {\n            \"aliases\": [],\n            \"category\": \"unknown\"\
  ,\n            \"name\": \"MILA - Quebec AI Institute \"\n          }\n        ],\n\
  \        \"author\": {\n          \"aliases\": [],\n          \"links\": [\n   \
  \         {\n              \"link\": \"http://iclr.cc/api/miniconf/users/84583?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Pablo Piantanida\"\n        },\n        \"display_name\": \"Pablo Piantanida\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"New York\
  \ University\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/84582?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Marco Romanelli\"\n        },\n        \"display_name\": \"Marco Romanelli\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"TU Wien Vienna\
  \ University of Technology\"\n          }\n        ],\n        \"author\": {\n \
  \         \"aliases\": [],\n          \"links\": [\n            {\n            \
  \  \"link\": \"http://iclr.cc/api/miniconf/users/46177?format=json\",\n        \
  \      \"type\": \"profile\"\n            }\n          ],\n          \"name\": \"\
  Georg Pichler\"\n        },\n        \"display_name\": \"Georg Pichler\"\n     \
  \ },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Universit\\\
  u00e9 Paris-Saclay CNRS CentraleSup\\u00e9lec\"\n          }\n        ],\n     \
  \   \"author\": {\n          \"aliases\": [],\n          \"links\": [\n        \
  \    {\n              \"link\": \"http://iclr.cc/api/miniconf/users/84601?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Eduardo Dadalto C\\u00e2mara Gomes\"\n        },\n        \"display_name\"\
  : \"Eduardo Dadalto C\\u00e2mara Gomes\"\n      }\n    ],\n    \"flags\": [],\n\
  \    \"links\": [\n      {\n        \"link\": \"https://iclr.cc/virtual/2024/poster/17676\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"https://openreview.net/forum?id=ruGY8v10mK\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"ruGY8v10mK\"\
  ,\n        \"type\": \"openreview\"\n      }\n    ],\n    \"releases\": [\n    \
  \  {\n        \"pages\": null,\n        \"status\": \"Accept (poster)\",\n     \
  \   \"venue\": {\n          \"aliases\": [],\n          \"date\": \"2024-05-07\"\
  ,\n          \"date_precision\": 3,\n          \"links\": [],\n          \"name\"\
  : \"ICLR\",\n          \"open\": true,\n          \"peer_reviewed\": true,\n   \
  \       \"publisher\": null,\n          \"series\": \"ICLR\",\n          \"type\"\
  : \"conference\",\n          \"volume\": null\n        }\n      }\n    ],\n    \"\
  title\": \"A Data-Driven Measure of Relative Uncertainty for Misclassification Detection\"\
  ,\n    \"topics\": [\n      {\n        \"name\": \"Theory->Everything Else\"\n \
  \     }\n    ]\n  },\n  {\n    \"abstract\": \"Model pruning is a popular approach\
  \ to enable the deployment of large deep learning models on edge devices with restricted\
  \ computational or storage capacities. Although sparse models achieve performance\
  \ comparable to that of their dense counterparts at the level of the entire dataset,\
  \ they exhibit high accuracy drops for some data sub-groups. Existing methods to\
  \ mitigate this disparate impact induced by pruning (i) rely on surrogate metrics\
  \ that address the problem indirectly and have limited interpretability; or (ii)\
  \ scale poorly with the number of protected sub-groups in terms of computational\
  \ cost. We propose a constrained optimization approach that _directly addresses\
  \ the disparate impact of pruning_: our formulation bounds the accuracy change between\
  \ the dense and sparse models, for each sub-group. This choice of constraints provides\
  \ an interpretable success criterion to determine if a pruned model achieves acceptable\
  \ disparity levels. Experimental results demonstrate that our technique scales reliably\
  \ to problems involving large models and hundreds of protected sub-groups.\",\n\
  \    \"authors\": [\n      {\n        \"affiliations\": [\n          {\n       \
  \     \"aliases\": [],\n            \"category\": \"unknown\",\n            \"name\"\
  : \"MILA\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/19670?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Meraj Hashemizadeh\"\n        },\n        \"display_name\": \"Meraj Hashemizadeh\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"McGill University\"\
  \n          }\n        ],\n        \"author\": {\n          \"aliases\": [],\n \
  \         \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/86123?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Golnoosh Farnadi\"\n        },\n        \"display_name\": \"Golnoosh Farnadi\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila &amp;amp;amp;amp;\
  \ U. of Montreal\"\n          }\n        ],\n        \"author\": {\n          \"\
  aliases\": [],\n          \"links\": [\n            {\n              \"link\": \"\
  http://iclr.cc/api/miniconf/users/86131?format=json\",\n              \"type\":\
  \ \"profile\"\n            }\n          ],\n          \"name\": \"Juan Ramirez\"\
  \n        },\n        \"display_name\": \"Juan Ramirez\"\n      },\n      {\n  \
  \      \"affiliations\": [\n          {\n            \"aliases\": [],\n        \
  \    \"category\": \"unknown\",\n            \"name\": \"Mila - University d\\u00e9\
  \ Montr\\u00e9al\"\n          }\n        ],\n        \"author\": {\n          \"\
  aliases\": [],\n          \"links\": [\n            {\n              \"link\": \"\
  http://iclr.cc/api/miniconf/users/31872?format=json\",\n              \"type\":\
  \ \"profile\"\n            }\n          ],\n          \"name\": \"Rohan Sukumaran\"\
  \n        },\n        \"display_name\": \"Rohan Sukumaran\"\n      },\n      {\n\
  \        \"affiliations\": [\n          {\n            \"aliases\": [],\n      \
  \      \"category\": \"unknown\",\n            \"name\": \"Mila, Universit\\u00e9\
  \ de Montr\\u00e9al & Samsung SAIL Montreal\"\n          }\n        ],\n       \
  \ \"author\": {\n          \"aliases\": [],\n          \"links\": [\n          \
  \  {\n              \"link\": \"http://iclr.cc/api/miniconf/users/1241?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Simon Lacoste-Julien\"\n        },\n        \"display_name\": \"Simon\
  \ Lacoste-Julien\"\n      },\n      {\n        \"affiliations\": [\n          {\n\
  \            \"aliases\": [],\n            \"category\": \"unknown\",\n        \
  \    \"name\": \"Mila, University of Montreal\"\n          }\n        ],\n     \
  \   \"author\": {\n          \"aliases\": [],\n          \"links\": [\n        \
  \    {\n              \"link\": \"http://iclr.cc/api/miniconf/users/33293?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Jose Gallego-Posada\"\n        },\n        \"display_name\": \"Jose Gallego-Posada\"\
  \n      }\n    ],\n    \"flags\": [],\n    \"links\": [\n      {\n        \"link\"\
  : \"Xz13DtbOVW\",\n        \"type\": \"openreview\"\n      },\n      {\n       \
  \ \"link\": \"https://iclr.cc/media/iclr-2024/Slides/18437.pdf\",\n        \"type\"\
  : \"slides\"\n      },\n      {\n        \"link\": \"https://iclr.cc/virtual/2024/poster/18437\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"https://openreview.net/forum?id=Xz13DtbOVW\"\
  ,\n        \"type\": \"abstract\"\n      }\n    ],\n    \"releases\": [\n      {\n\
  \        \"pages\": null,\n        \"status\": \"Accept (poster)\",\n        \"\
  venue\": {\n          \"aliases\": [],\n          \"date\": \"2024-05-07\",\n  \
  \        \"date_precision\": 3,\n          \"links\": [],\n          \"name\": \"\
  ICLR\",\n          \"open\": true,\n          \"peer_reviewed\": true,\n       \
  \   \"publisher\": null,\n          \"series\": \"ICLR\",\n          \"type\": \"\
  conference\",\n          \"volume\": null\n        }\n      }\n    ],\n    \"title\"\
  : \"Balancing Act: Constraining Disparate Impact in Sparse Models\",\n    \"topics\"\
  : [\n      {\n        \"name\": \"Social Aspects->Trustworthy Machine Learning\"\
  \n      }\n    ]\n  },\n  {\n    \"abstract\": \"Representations are at the core\
  \ of all deep reinforcement learning (RL) methods for both Markov decision processes\
  \ (MDPs) and partially observable Markov decision processes (POMDPs). Many representation\
  \ learning methods and theoretical frameworks have been developed to understand\
  \ what constitutes an effective representation. However, the relationships between\
  \ these methods and the shared properties among them remain unclear. In this paper,\
  \ we show that many of these seemingly distinct methods and frameworks for state\
  \ and history abstractions are, in fact, based on a common idea of self-predictive\
  \ abstraction. Furthermore, we provide theoretical insights into the widely adopted\
  \ objectives and optimization, such as the stop-gradient technique, in learning\
  \ self-predictive representations. These findings together yield a minimalist algorithm\
  \ to learn self-predictive representations for states and histories. We validate\
  \ our theories by applying our algorithm to standard MDPs, MDPs with distractors,\
  \ and POMDPs with sparse rewards. These findings culminate in a set of preliminary\
  \ guidelines for RL practitioners.\",\n    \"authors\": [\n      {\n        \"affiliations\"\
  : [],\n        \"author\": {\n          \"aliases\": [],\n          \"links\": [\n\
  \            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/19539?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Erfan Seyedsalehi\"\n        },\n        \"display_name\": \"Erfan Seyedsalehi\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Carnegie\
  \ Mellon University\"\n          }\n        ],\n        \"author\": {\n        \
  \  \"aliases\": [],\n          \"links\": [\n            {\n              \"link\"\
  : \"http://iclr.cc/api/miniconf/users/5191?format=json\",\n              \"type\"\
  : \"profile\"\n            }\n          ],\n          \"name\": \"Benjamin Eysenbach\"\
  \n        },\n        \"display_name\": \"Benjamin Eysenbach\"\n      },\n     \
  \ {\n        \"affiliations\": [\n          {\n            \"aliases\": [],\n  \
  \          \"category\": \"unknown\",\n            \"name\": \"Massachusetts Institute\
  \ of Technology\"\n          }\n        ],\n        \"author\": {\n          \"\
  aliases\": [],\n          \"links\": [\n            {\n              \"link\": \"\
  http://iclr.cc/api/miniconf/users/52158?format=json\",\n              \"type\":\
  \ \"profile\"\n            }\n          ],\n          \"name\": \"Clement Gehring\"\
  \n        },\n        \"display_name\": \"Clement Gehring\"\n      },\n      {\n\
  \        \"affiliations\": [\n          {\n            \"aliases\": [],\n      \
  \      \"category\": \"unknown\",\n            \"name\": \"McGill University\"\n\
  \          }\n        ],\n        \"author\": {\n          \"aliases\": [],\n  \
  \        \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/50499?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Aditya Mahajan\"\n        },\n        \"display_name\": \"Aditya Mahajan\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila -- Quebec\
  \ AI Institute\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/51945?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Tianwei Ni\"\n        },\n        \"display_name\": \"Tianwei Ni\"\n \
  \     },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Mila, University\
  \ of Montreal\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/85025?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Michel Ma\"\n        },\n        \"display_name\": \"Michel Ma\"\n   \
  \   },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"Universit\\\
  u00e9 de Montr\\u00e9al, Mila\"\n          }\n        ],\n        \"author\": {\n\
  \          \"aliases\": [],\n          \"links\": [\n            {\n           \
  \   \"link\": \"http://iclr.cc/api/miniconf/users/99678?format=json\",\n       \
  \       \"type\": \"profile\"\n            }\n          ],\n          \"name\":\
  \ \"Pierre-Luc Bacon\"\n        },\n        \"display_name\": \"Pierre-Luc Bacon\"\
  \n      }\n    ],\n    \"flags\": [],\n    \"links\": [\n      {\n        \"link\"\
  : \"https://iclr.cc/virtual/2024/poster/17879\",\n        \"type\": \"abstract\"\
  \n      },\n      {\n        \"link\": \"https://openreview.net/forum?id=ms0VgzSGF2\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"ms0VgzSGF2\"\
  ,\n        \"type\": \"openreview\"\n      }\n    ],\n    \"releases\": [\n    \
  \  {\n        \"pages\": null,\n        \"status\": \"Accept (poster)\",\n     \
  \   \"venue\": {\n          \"aliases\": [],\n          \"date\": \"2024-05-07\"\
  ,\n          \"date_precision\": 3,\n          \"links\": [],\n          \"name\"\
  : \"ICLR\",\n          \"open\": true,\n          \"peer_reviewed\": true,\n   \
  \       \"publisher\": null,\n          \"series\": \"ICLR\",\n          \"type\"\
  : \"conference\",\n          \"volume\": null\n        }\n      }\n    ],\n    \"\
  title\": \"Bridging State and History Representations: Understanding Self-Predictive\
  \ RL\",\n    \"topics\": [\n      {\n        \"name\": \"Reinforcement Learning->Deep\
  \ RL\"\n      }\n    ]\n  },\n  {\n    \"abstract\": \"Understanding and developing\
  \ optimal representations has long been foundational in machine learning (ML). While\
  \ disentangled representations have shown promise in generative modeling and representation\
  \ learning, their downstream usefulness remains debated. Recent studies re-defined\
  \ disentanglement through a formal connection to symmetries, emphasizing the ability\
  \ to reduce latent domains (i.e., ML problem spaces) and consequently enhance data\
  \ efficiency and generative capabilities. However, from an information theory viewpoint,\
  \ assigning a complex attribute (i.e., features) to a specific latent variable may\
  \ be infeasible, limiting the applicability of disentangled representations to simple\
  \ datasets. In this work, we introduce $\\\\alpha$-TCVAE, a variational autoencoder\
  \ optimized using a novel total correlation (TC) lower bound that maximizes disentanglement\
  \ and latent variables informativeness. The proposed TC bound is grounded in information\
  \ theory constructs, generalizes the $\\\\beta$-VAE lower bound, and can be reduced\
  \ to a convex combination of the known variational information bottleneck (VIB)\
  \ and conditional entropy bottleneck (CEB) terms. Moreover, we present quantitative\
  \ analyses and correlation studies that support the idea that smaller latent domains\
  \ (i.e., disentangled representations) lead to better generative capabilities and\
  \ diversity. Additionally, we perform downstream task experiments from both representation\
  \ and RL domains to assess our questions from a broader ML perspective. Our results\
  \ demonstrate that $\\\\alpha$-TCVAE consistently learns more disentangled representations\
  \ than baselines and generates more diverse observations without sacrificing visual\
  \ fidelity. Notably, $\\\\alpha$-TCVAE exhibits marked improvements on MPI3D-Real,\
  \ the most realistic disentangled dataset in our study,  confirming its ability\
  \ to represent complex datasets when maximizing the informativeness of individual\
  \ variables. Finally, testing the proposed model off-the-shelf on a state-of-the-art\
  \ model-based RL agent, Director, significantly shows $\\\\alpha$-TCVAE downstream\
  \ usefulness on the loconav Ant Maze task. Implementation available at https://github.com/Cmeo97/Alpha-TCVAE\"\
  ,\n    \"authors\": [\n      {\n        \"affiliations\": [\n          {\n     \
  \       \"aliases\": [],\n            \"category\": \"unknown\",\n            \"\
  name\": \"Delft University of Technology\"\n          }\n        ],\n        \"\
  author\": {\n          \"aliases\": [],\n          \"links\": [\n            {\n\
  \              \"link\": \"http://iclr.cc/api/miniconf/users/69054?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Justin Dauwels\"\n        },\n        \"display_name\": \"Justin Dauwels\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"MILA, University\
  \ of Montreal\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/3239?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Anirudh Goyal\"\n        },\n        \"display_name\": \"Anirudh Goyal\"\
  \n      },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"School of\
  \ Informatics, University of Edinburgh\"\n          }\n        ],\n        \"author\"\
  : {\n          \"aliases\": [],\n          \"links\": [\n            {\n       \
  \       \"link\": \"http://iclr.cc/api/miniconf/users/100268?format=json\",\n  \
  \            \"type\": \"profile\"\n            }\n          ],\n          \"name\"\
  : \"Louis Mahon\"\n        },\n        \"display_name\": \"Louis Mahon\"\n     \
  \ },\n      {\n        \"affiliations\": [\n          {\n            \"aliases\"\
  : [],\n            \"category\": \"unknown\",\n            \"name\": \"TUDelft -\
  \ Mila\"\n          }\n        ],\n        \"author\": {\n          \"aliases\"\
  : [],\n          \"links\": [\n            {\n              \"link\": \"http://iclr.cc/api/miniconf/users/53796?format=json\"\
  ,\n              \"type\": \"profile\"\n            }\n          ],\n          \"\
  name\": \"Cristian Meo\"\n        },\n        \"display_name\": \"Cristian Meo\"\
  \n      }\n    ],\n    \"flags\": [],\n    \"links\": [\n      {\n        \"link\"\
  : \"https://iclr.cc/virtual/2024/poster/17762\",\n        \"type\": \"abstract\"\
  \n      },\n      {\n        \"link\": \"https://openreview.net/forum?id=ptXo0epLQo\"\
  ,\n        \"type\": \"abstract\"\n      },\n      {\n        \"link\": \"ptXo0epLQo\"\
  ,\n        \"type\": \"openreview\"\n      }\n    ],\n    \"releases\": [\n    \
  \  {\n        \"pages\": null,\n        \"status\": \"Accept (poster)\",\n     \
  \   \"venue\": {\n          \"aliases\": [],\n          \"date\": \"2024-05-07\"\
  ,\n          \"date_precision\": 3,\n          \"links\": [],\n          \"name\"\
  : \"ICLR\",\n          \"open\": true,\n          \"peer_reviewed\": true,\n   \
  \       \"publisher\": null,\n          \"series\": \"ICLR\",\n          \"type\"\
  : \"conference\",\n          \"volume\": null\n        }\n      }\n    ],\n    \"\
  title\": \"$\\\\alpha$TC-VAE: On the relationship between Disentanglement and Diversity\"\
  ,\n    \"topics\": [\n      {\n        \"name\": \"Deep Learning->Other Representation\
  \ Learning\"\n      }\n    ]\n  }\n]"
