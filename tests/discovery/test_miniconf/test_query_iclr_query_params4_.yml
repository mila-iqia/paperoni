- info:
    discovered_by:
      miniconf: iclr:40dba662fae60cd3bcceaa76a82d2873
  key: miniconf:iclr:40dba662fae60cd3bcceaa76a82d2873
  paper:
    abstract: Understanding and developing optimal representations has long been foundational
      in machine learning (ML). While disentangled representations have shown promise
      in generative modeling and representation learning, their downstream usefulness
      remains debated. Recent studies re-defined disentanglement through a formal
      connection to symmetries, emphasizing the ability to reduce latent domains (i.e.,
      ML problem spaces) and consequently enhance data efficiency and generative capabilities.
      However, from an information theory viewpoint, assigning a complex attribute
      (i.e., features) to a specific latent variable may be infeasible, limiting the
      applicability of disentangled representations to simple datasets. In this work,
      we introduce $\alpha$-TCVAE, a variational autoencoder optimized using a novel
      total correlation (TC) lower bound that maximizes disentanglement and latent
      variables informativeness. The proposed TC bound is grounded in information
      theory constructs, generalizes the $\beta$-VAE lower bound, and can be reduced
      to a convex combination of the known variational information bottleneck (VIB)
      and conditional entropy bottleneck (CEB) terms. Moreover, we present quantitative
      analyses and correlation studies that support the idea that smaller latent domains
      (i.e., disentangled representations) lead to better generative capabilities
      and diversity. Additionally, we perform downstream task experiments from both
      representation and RL domains to assess our questions from a broader ML perspective.
      Our results demonstrate that $\alpha$-TCVAE consistently learns more disentangled
      representations than baselines and generates more diverse observations without
      sacrificing visual fidelity. Notably, $\alpha$-TCVAE exhibits marked improvements
      on MPI3D-Real, the most realistic disentangled dataset in our study,  confirming
      its ability to represent complex datasets when maximizing the informativeness
      of individual variables. Finally, testing the proposed model off-the-shelf on
      a state-of-the-art model-based RL agent, Director, significantly shows $\alpha$-TCVAE
      downstream usefulness on the loconav Ant Maze task. Implementation available
      at https://github.com/Cmeo97/Alpha-TCVAE
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: TUDelft - Mila
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/53796?format=json
          type: profile
        name: Cristian Meo
      display_name: Cristian Meo
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: School of Informatics, University of Edinburgh
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/100268?format=json
          type: profile
        name: Louis Mahon
      display_name: Louis Mahon
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: MILA, University of Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/3239?format=json
          type: profile
        name: Anirudh Goyal
      display_name: Anirudh Goyal
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Delft University of Technology
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/69054?format=json
          type: profile
        name: Justin Dauwels
      display_name: Justin Dauwels
    flags: []
    links:
    - link: https://iclr.cc/virtual/2024/poster/17762
      type: abstract
    - link: ptXo0epLQo
      type: openreview
    - link: iclr/2024-05-07/40dba662fae60cd3bcceaa76a82d2873
      type: uid
    releases:
    - pages: null
      status: Accept (poster)
      venue:
        aliases: []
        date: '2024-05-07'
        date_precision: 3
        index: null
        links: []
        name: ICLR
        open: true
        peer_reviewed: true
        publisher: null
        series: ICLR
        short_name: null
        type: conference
        volume: null
    title: '$\alpha$TC-VAE: On the relationship between Disentanglement and Diversity'
    topics:
    - name: Deep Learning->Other Representation Learning
  score: 0.0
- info:
    discovered_by:
      miniconf: iclr:6be5336db2c119736cf48f475e051bfe
  key: miniconf:iclr:6be5336db2c119736cf48f475e051bfe
  paper:
    abstract: Misclassification detection is an important problem in machine learning,
      as it allows for the identification of instances where the model's predictions
      are unreliable. However, conventional uncertainty measures such as Shannon entropy
      do not provide an effective way to infer the real uncertainty associated with
      the model's predictions. In this paper, we introduce a novel data-driven measure
      of uncertainty relative to an observer for misclassification detection. By learning
      patterns in the distribution of soft-predictions, our uncertainty measure can
      identify misclassified samples based on the predicted class probabilities.  Interestingly,
      according to the proposed measure, soft-predictions corresponding to misclassified
      instances can carry a large amount of uncertainty, even though they may have
      low Shannon entropy. We demonstrate empirical improvements over multiple image
      classification tasks, outperforming state-of-the-art misclassification detection
      methods.
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Université Paris-Saclay CNRS CentraleSupélec
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/84601?format=json
          type: profile
        name: Eduardo Dadalto Câmara Gomes
      display_name: Eduardo Dadalto Câmara Gomes
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: New York University
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/84582?format=json
          type: profile
        name: Marco Romanelli
      display_name: Marco Romanelli
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: TU Wien Vienna University of Technology
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/46177?format=json
          type: profile
        name: Georg Pichler
      display_name: Georg Pichler
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: 'MILA - Quebec AI Institute '
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/84583?format=json
          type: profile
        name: Pablo Piantanida
      display_name: Pablo Piantanida
    flags: []
    links:
    - link: https://iclr.cc/virtual/2024/poster/17676
      type: abstract
    - link: ruGY8v10mK
      type: openreview
    - link: iclr/2024-05-07/6be5336db2c119736cf48f475e051bfe
      type: uid
    releases:
    - pages: null
      status: Accept (poster)
      venue:
        aliases: []
        date: '2024-05-07'
        date_precision: 3
        index: null
        links: []
        name: ICLR
        open: true
        peer_reviewed: true
        publisher: null
        series: ICLR
        short_name: null
        type: conference
        volume: null
    title: A Data-Driven Measure of Relative Uncertainty for Misclassification Detection
    topics:
    - name: Theory->Everything Else
  score: 0.0
- info:
    discovered_by:
      miniconf: iclr:7f53f8c6c730af6aeb52e66eb74d8507
  key: miniconf:iclr:7f53f8c6c730af6aeb52e66eb74d8507
  paper:
    abstract: 'Autoregressive large language models (LLMs) compress knowledge from
      their training data through next-token conditional distributions. This limits
      tractable querying of this knowledge to start-to-end autoregressive sampling.
      However, many tasks of interest---including sequence continuation, infilling,
      and other forms of constrained generation---involve sampling from intractable
      posterior distributions. We address this limitation by using amortized Bayesian
      inference to sample from these intractable posteriors. Such amortization is
      algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement
      learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate
      that this distribution-matching paradigm of LLM fine-tuning can serve as an
      effective alternative to maximum-likelihood training and reward-maximizing policy
      optimization. As an important application, we interpret chain-of-thought reasoning
      as a latent variable modeling problem and demonstrate that our approach enables
      data-efficient adaptation of LLMs to tasks that require multi-step rationalization
      and tool use.'
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/49551?format=json
          type: profile
        name: Edward Hu
      display_name: Edward Hu
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, Université de Montréal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/19397?format=json
          type: profile
        name: Moksh Jain
      display_name: Moksh Jain
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/32612?format=json
          type: profile
        name: Eric Elmoznino
      display_name: Eric Elmoznino
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: University of Oxford
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/86716?format=json
          type: profile
        name: Younesse Kaddar
      display_name: Younesse Kaddar
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, Quebec AI institute
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/43856?format=json
          type: profile
        name: Guillaume Lajoie
      display_name: Guillaume Lajoie
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, University of Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/6784?format=json
          type: profile
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila / Université de Montréal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/6671?format=json
          type: profile
        name: Nikolay Malkin
      display_name: Nikolay Malkin
    flags: []
    links:
    - link: https://iclr.cc/virtual/2024/poster/18725
      type: abstract
    - link: 2024-Oral--1391-05763559
      type: openreview
    - link: Ouj6p4ca60
      type: openreview
    - link: https://iclr.cc/media/iclr-2024/Slides/18725.pdf
      type: slides
    - link: iclr/2024-05-07/7f53f8c6c730af6aeb52e66eb74d8507
      type: uid
    releases:
    - pages: null
      status: Accept (oral)
      venue:
        aliases: []
        date: '2024-05-07'
        date_precision: 3
        index: null
        links: []
        name: ICLR
        open: true
        peer_reviewed: true
        publisher: null
        series: ICLR
        short_name: null
        type: conference
        volume: null
    title: Amortizing intractable inference in large language models
    topics:
    - name: Deep Learning->Large Language Models
  score: 0.0
- info:
    discovered_by:
      miniconf: iclr:92af93f73faf3cefc129b6bc55a748a9
  key: miniconf:iclr:92af93f73faf3cefc129b6bc55a748a9
  paper:
    abstract: 'Model pruning is a popular approach to enable the deployment of large
      deep learning models on edge devices with restricted computational or storage
      capacities. Although sparse models achieve performance comparable to that of
      their dense counterparts at the level of the entire dataset, they exhibit high
      accuracy drops for some data sub-groups. Existing methods to mitigate this disparate
      impact induced by pruning (i) rely on surrogate metrics that address the problem
      indirectly and have limited interpretability; or (ii) scale poorly with the
      number of protected sub-groups in terms of computational cost. We propose a
      constrained optimization approach that _directly addresses the disparate impact
      of pruning_: our formulation bounds the accuracy change between the dense and
      sparse models, for each sub-group. This choice of constraints provides an interpretable
      success criterion to determine if a pruned model achieves acceptable disparity
      levels. Experimental results demonstrate that our technique scales reliably
      to problems involving large models and hundreds of protected sub-groups.'
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: MILA
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/19670?format=json
          type: profile
        name: Meraj Hashemizadeh
      display_name: Meraj Hashemizadeh
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila &amp;amp;amp;amp; U. of Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/86131?format=json
          type: profile
        name: Juan Ramirez
      display_name: Juan Ramirez
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila - University dé Montréal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/31872?format=json
          type: profile
        name: Rohan Sukumaran
      display_name: Rohan Sukumaran
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: McGill University
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/86123?format=json
          type: profile
        name: Golnoosh Farnadi
      display_name: Golnoosh Farnadi
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, Université de Montréal & Samsung SAIL Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/1241?format=json
          type: profile
        name: Simon Lacoste-Julien
      display_name: Simon Lacoste-Julien
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, University of Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/33293?format=json
          type: profile
        name: Jose Gallego-Posada
      display_name: Jose Gallego-Posada
    flags: []
    links:
    - link: https://iclr.cc/virtual/2024/poster/18437
      type: abstract
    - link: Xz13DtbOVW
      type: openreview
    - link: https://iclr.cc/media/iclr-2024/Slides/18437.pdf
      type: slides
    - link: iclr/2024-05-07/92af93f73faf3cefc129b6bc55a748a9
      type: uid
    releases:
    - pages: null
      status: Accept (poster)
      venue:
        aliases: []
        date: '2024-05-07'
        date_precision: 3
        index: null
        links: []
        name: ICLR
        open: true
        peer_reviewed: true
        publisher: null
        series: ICLR
        short_name: null
        type: conference
        volume: null
    title: 'Balancing Act: Constraining Disparate Impact in Sparse Models'
    topics:
    - name: Social Aspects->Trustworthy Machine Learning
  score: 0.0
- info:
    discovered_by:
      miniconf: iclr:a9be4c2a4041cadbf9d61ae16dd1389e
  key: miniconf:iclr:a9be4c2a4041cadbf9d61ae16dd1389e
  paper:
    abstract: Representations are at the core of all deep reinforcement learning (RL)
      methods for both Markov decision processes (MDPs) and partially observable Markov
      decision processes (POMDPs). Many representation learning methods and theoretical
      frameworks have been developed to understand what constitutes an effective representation.
      However, the relationships between these methods and the shared properties among
      them remain unclear. In this paper, we show that many of these seemingly distinct
      methods and frameworks for state and history abstractions are, in fact, based
      on a common idea of self-predictive abstraction. Furthermore, we provide theoretical
      insights into the widely adopted objectives and optimization, such as the stop-gradient
      technique, in learning self-predictive representations. These findings together
      yield a minimalist algorithm to learn self-predictive representations for states
      and histories. We validate our theories by applying our algorithm to standard
      MDPs, MDPs with distractors, and POMDPs with sparse rewards. These findings
      culminate in a set of preliminary guidelines for RL practitioners.
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila -- Quebec AI Institute
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/51945?format=json
          type: profile
        name: Tianwei Ni
      display_name: Tianwei Ni
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Carnegie Mellon University
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/5191?format=json
          type: profile
        name: Benjamin Eysenbach
      display_name: Benjamin Eysenbach
    - affiliations: []
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/19539?format=json
          type: profile
        name: Erfan Seyedsalehi
      display_name: Erfan Seyedsalehi
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Mila, University of Montreal
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/85025?format=json
          type: profile
        name: Michel Ma
      display_name: Michel Ma
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Massachusetts Institute of Technology
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/52158?format=json
          type: profile
        name: Clement Gehring
      display_name: Clement Gehring
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: McGill University
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/50499?format=json
          type: profile
        name: Aditya Mahajan
      display_name: Aditya Mahajan
    - affiliations:
      - aliases: []
        category: unknown
        country: null
        name: Université de Montréal, Mila
      author:
        aliases: []
        links:
        - link: http://iclr.cc/api/miniconf/users/99678?format=json
          type: profile
        name: Pierre-Luc Bacon
      display_name: Pierre-Luc Bacon
    flags: []
    links:
    - link: https://iclr.cc/virtual/2024/poster/17879
      type: abstract
    - link: ms0VgzSGF2
      type: openreview
    - link: iclr/2024-05-07/a9be4c2a4041cadbf9d61ae16dd1389e
      type: uid
    releases:
    - pages: null
      status: Accept (poster)
      venue:
        aliases: []
        date: '2024-05-07'
        date_precision: 3
        index: null
        links: []
        name: ICLR
        open: true
        peer_reviewed: true
        publisher: null
        series: ICLR
        short_name: null
        type: conference
        volume: null
    title: 'Bridging State and History Representations: Understanding Self-Predictive
      RL'
    topics:
    - name: Reinforcement Learning->Deep RL
  score: 0.0
