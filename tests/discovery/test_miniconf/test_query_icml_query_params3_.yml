- key: miniconf:icml:bb1662b7c5f22a0f905fd59e718ca05e
  paper:
    abstract: We present a performant, general-purpose gradient-guided nested sampling
      (GGNS) algorithm, combining the state of the art in differentiable programming,
      Hamiltonian slice sampling, clustering, mode separation, dynamic nested sampling,
      and parallelization. This unique combination allows GGNS to scale well with
      dimensionality and perform competitively on a variety of synthetic and real-world
      problems. We also show the potential of combining nested sampling with generative
      flow networks to obtain large amounts of high-quality samples from the posterior
      distribution. This combination leads to faster mode discovery and more accurate
      estimates of the partition function.
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        name: Montreal Institute for Learning Algorithms, University of Montreal,
          Université de Montréal
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/123588?format=json
          type: profile
        name: Pablo Lemos
      display_name: Pablo Lemos
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila / Université de Montréal
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/69704?format=json
          type: profile
        name: Nikolay Malkin
      display_name: Nikolay Malkin
    - affiliations:
      - aliases: []
        category: unknown
        name: University of Cambridge
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/125397?format=json
          type: profile
        name: Will Handley
      display_name: Will Handley
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila - Quebec AI Institute
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/24659?format=json
          type: profile
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila / Ciela
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/94403?format=json
          type: profile
        name: Yashar Hezaveh
      display_name: Yashar Hezaveh
    - affiliations:
      - aliases: []
        category: unknown
        name: Université de Montréal and Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/76078?format=json
          type: profile
        name: Laurence Perreault-Levasseur
      display_name: Laurence Perreault-Levasseur
    flags: []
    links:
    - link: https://proceedings.mlr.press/v235/lemos24a.html
      type: pdf
    - link: https://icml.cc/virtual/2024/poster/34356
      type: abstract
    releases:
    - pages: null
      status: Accept (Poster)
      venue:
        aliases: []
        date: '2024-07-23'
        date_precision: 3
        links: []
        name: ICML
        open: true
        peer_reviewed: true
        publisher: null
        series: ICML
        type: conference
        volume: null
    title: Improving Gradient-Guided Nested Sampling for Posterior Inference
    topics:
    - name: Probabilistic Methods->Monte Carlo and Sampling Methods
  update_key: null
- key: miniconf:icml:63eb58bd4d3486f001438f911a11d323
  paper:
    abstract: Efficiently generating statistically independent samples from an unnormalized
      probability distribution, such as equilibrium samples of many-body systems,
      is a foundational problem in science. In this paper, we propose Iterated Denoising
      Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic
      score matching objective leveraging solely the energy function and its gradient---and
      no data samples---to train a diffusion-based sampler. Specifically, iDEM alternates
      between (I) sampling regions of high model density from a diffusion-based sampler
      and (II) using these samples in our stochastic matching objective to further
      improve the sampler. iDEM is scalable to high dimensions as the inner matching
      objective, is *simulation-free*, and requires no MCMC samples. Moreover, by
      leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the
      energy landscape enabling efficient exploration and learning of an amortized
      sampler. We evaluate iDEM on a suite of tasks ranging from standard synthetic
      energy functions to invariant $n$-body particle systems. We show that the proposed
      approach achieves state-of-the-art performance on all metrics and trains $2-5\times$
      faster, which allows it to be the first method to train using energy on the
      challenging $55$-particle Lennard-Jones system.
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        name: McGill-Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/56442?format=json
          type: profile
        name: Tara Akhound-Sadegh
      display_name: Tara Akhound-Sadegh
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila, Universite de Montreal
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/72991?format=json
          type: profile
        name: Jarrid Rector-Brooks
      display_name: Jarrid Rector-Brooks
    - affiliations:
      - aliases: []
        category: unknown
        name: University of Oxford Department of Computer Science
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/27183?format=json
          type: profile
        name: Joey Bose
      display_name: Joey Bose
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/40190?format=json
          type: profile
        name: Sarthak Mittal
      display_name: Sarthak Mittal
    - affiliations:
      - aliases: []
        category: unknown
        name: Montreal Institute for Learning Algorithms, University of Montreal,
          Université de Montréal
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/123588?format=json
          type: profile
        name: Pablo Lemos
      display_name: Pablo Lemos
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila - Quebec AI Institute; DreamFold
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/96459?format=json
          type: profile
        name: Chenghao Liu
      display_name: Chenghao Liu
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila - Quebec AI Institute, UdeM, Jagiellonian University
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/42889?format=json
          type: profile
        name: Marcin Sendera
      display_name: Marcin Sendera
    - affiliations:
      - aliases: []
        category: unknown
        name: McGill - Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/8224?format=json
          type: profile
        name: Siamak Ravanbakhsh
      display_name: Siamak Ravanbakhsh
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/73156?format=json
          type: profile
        name: Gauthier Gidel
      display_name: Gauthier Gidel
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila - Quebec AI Institute
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/24659?format=json
          type: profile
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila / Université de Montréal
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/69704?format=json
          type: profile
        name: Nikolay Malkin
      display_name: Nikolay Malkin
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/92402?format=json
          type: profile
        name: Alexander Tong
      display_name: Alexander Tong
    flags: []
    links:
    - link: https://proceedings.mlr.press/v235/akhound-sadegh24a.html
      type: pdf
    - link: https://icml.cc/virtual/2024/poster/33422
      type: abstract
    releases:
    - pages: null
      status: Accept (Poster)
      venue:
        aliases: []
        date: '2024-07-23'
        date_precision: 3
        links: []
        name: ICML
        open: true
        peer_reviewed: true
        publisher: null
        series: ICML
        type: conference
        volume: null
    title: Iterated Denoising Energy Matching for Sampling from Boltzmann Densities
    topics:
    - name: Probabilistic Methods->Monte Carlo and Sampling Methods
  update_key: null
- key: miniconf:icml:cf1f78fe923afe05f7597da2be7a3da8
  paper:
    abstract: Neural Processes (NPs) are popular meta-learning methods for efficiently
      modelling predictive uncertainty. Recent state-of-the-art methods, however,
      leverage expensive attention mechanisms, limiting their applications, particularly
      in low-resource settings. In this work, we propose Constant Memory Attentive
      Neural Processes (CMANPs), an NP variant that only requires **constant** memory.
      To do so, we first propose an efficient update operation for Cross Attention.
      Leveraging the update operation, we propose Constant Memory Attention Block
      (CMAB), a novel attention block that (i) is permutation invariant, (ii) computes
      its output in constant memory, and (iii) performs constant computation updates.
      Finally, building on CMAB, we detail Constant Memory Attentive Neural Processes.
      Empirically, we show CMANPs achieve state-of-the-art results on popular NP benchmarks
      while being significantly more memory efficient than prior methods.
    authors:
    - affiliations:
      - aliases: []
        category: unknown
        name: Borealis AI & Mila
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/55140?format=json
          type: profile
        name: Leo Feng
      display_name: Leo Feng
    - affiliations:
      - aliases: []
        category: unknown
        name: Borealis AI
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/72356?format=json
          type: profile
        name: Frederick Tung
      display_name: Frederick Tung
    - affiliations:
      - aliases: []
        category: unknown
        name: Oracle Labs
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/8111?format=json
          type: profile
        name: Hossein Hajimirsadeghi
      display_name: Hossein Hajimirsadeghi
    - affiliations:
      - aliases: []
        category: unknown
        name: Mila - Quebec AI Institute
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/24659?format=json
          type: profile
        name: Yoshua Bengio
      display_name: Yoshua Bengio
    - affiliations:
      - aliases: []
        category: unknown
        name: Borealis AI
      author:
        aliases: []
        links:
        - link: http://icml.cc/api/miniconf/users/25292?format=json
          type: profile
        name: Mohamed Osama Ahmed
      display_name: Mohamed Osama Ahmed
    flags: []
    links:
    - link: https://proceedings.mlr.press/v235/feng24i.html
      type: pdf
    - link: https://icml.cc/virtual/2024/poster/32689
      type: abstract
    releases:
    - pages: null
      status: Accept (Poster)
      venue:
        aliases: []
        date: '2024-07-23'
        date_precision: 3
        links: []
        name: ICML
        open: true
        peer_reviewed: true
        publisher: null
        series: ICML
        type: conference
        volume: null
    title: Memory Efficient Neural Processes via Constant Memory Attention Block
    topics:
    - name: Deep Learning->Attention Mechanisms
  update_key: null
