[
  {
    "abstract": "Bayesian Persuasion is proposed as a tool for social media platforms to combat the spread of misinformation. Since platforms can use machine learning to predict the popularity and misinformation features of to-be-shared posts, and users are largely motivated to share popular content, platforms can strategically signal this informational advantage to change user beliefs and persuade them not to share misinformation. We characterize the optimal signaling scheme with imperfect predictions as a linear program and give sufficient and necessary conditions on the classifier to ensure optimal platform utility is non-decreasing and continuous. Next, this interaction is considered under a performative model, wherein platform intervention affects the user's future behaviour. The convergence and stability of optimal signaling under this performative process are fully characterized. Lastly, we experimentally validate that our approach significantly reduces misinformation in both the single round and performative setting.",
    "authors": [
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Harvard University"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/124592?format=json",
              "type": "profile"
            }
          ],
          "name": "Safwan Hossain"
        },
        "display_name": "Safwan Hossain"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Harvard University"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/19475?format=json",
              "type": "profile"
            }
          ],
          "name": "Yiling Chen"
        },
        "display_name": "Yiling Chen"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Mila"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/73156?format=json",
              "type": "profile"
            }
          ],
          "name": "Gauthier Gidel"
        },
        "display_name": "Gauthier Gidel"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/124566?format=json",
              "type": "profile"
            }
          ],
          "name": "Andjela Mladenovic"
        },
        "display_name": "Andjela Mladenovic"
      }
    ],
    "flags": [],
    "links": [
      {
        "link": "https://icml.cc/media/icml-2024/Slides/33949_ypaq1v1.pdf",
        "type": "slides"
      },
      {
        "link": "https://icml.cc/virtual/2024/poster/33949",
        "type": "abstract"
      },
      {
        "link": "https://proceedings.mlr.press/v235/hossain24b.html",
        "type": "pdf"
      }
    ],
    "releases": [
      {
        "pages": null,
        "status": "Accept (Poster)",
        "venue": {
          "aliases": [],
          "date": "2024-07-23",
          "date_precision": 3,
          "links": [],
          "name": "ICML",
          "open": true,
          "peer_reviewed": true,
          "publisher": null,
          "series": "ICML",
          "type": "conference",
          "volume": null
        }
      }
    ],
    "title": "A Persuasive Approach to Combating Misinformation",
    "topics": []
  },
  {
    "abstract": "Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variables by enforcing sparsity in the inferred representation. Experiments on different simulated datasets and established benchmarks highlight the effectiveness of our approach in recovering the ground-truth latents.",
    "authors": [
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "ISTA"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/103725?format=json",
              "type": "profile"
            }
          ],
          "name": "Francesco Locatello"
        },
        "display_name": "Francesco Locatello"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "ISTA"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/128685?format=json",
              "type": "profile"
            }
          ],
          "name": "Dingling Yao"
        },
        "display_name": "Dingling Yao"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "MPI for Intelligent Systems, T\u00fcbingen & University of Cambridge"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/58738?format=json",
              "type": "profile"
            }
          ],
          "name": "Julius von K\u00fcgelgen"
        },
        "display_name": "Julius von K\u00fcgelgen"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Service Now"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/62187?format=json",
              "type": "profile"
            }
          ],
          "name": "Perouz Taslakian"
        },
        "display_name": "Perouz Taslakian"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Universit\u00e9 de Montr\u00e9al, Mila"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/62189?format=json",
              "type": "profile"
            }
          ],
          "name": "S\u00e9bastien Lachapelle"
        },
        "display_name": "S\u00e9bastien Lachapelle"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "University of Amsterdam"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/125181?format=json",
              "type": "profile"
            }
          ],
          "name": "Danru Xu"
        },
        "display_name": "Danru Xu"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "University of Amsterdam, MIT-IBM Watson AI Lab"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/73085?format=json",
              "type": "profile"
            }
          ],
          "name": "Sara Magliacane"
        },
        "display_name": "Sara Magliacane"
      }
    ],
    "flags": [],
    "links": [
      {
        "link": "https://icml.cc/virtual/2024/poster/34245",
        "type": "abstract"
      },
      {
        "link": "https://proceedings.mlr.press/v235/xu24ac.html",
        "type": "pdf"
      }
    ],
    "releases": [
      {
        "pages": null,
        "status": "Accept (Poster)",
        "venue": {
          "aliases": [],
          "date": "2024-07-23",
          "date_precision": 3,
          "links": [],
          "name": "ICML",
          "open": true,
          "peer_reviewed": true,
          "publisher": null,
          "series": "ICML",
          "type": "conference",
          "volume": null
        }
      }
    ],
    "title": "A Sparsity Principle for Partially Observable Causal Representation Learning",
    "topics": [
      {
        "name": "Miscellaneous Aspects of Machine Learning->Causality"
      }
    ]
  },
  {
    "abstract": "Second-order Recurrent Neural Networks (2RNNs) extend RNNs by leveraging second-order interactions for sequence modelling. These models are provably more expressive than their first-order counterparts and have connections to well-studied models from formal language theory. However, their large parameter tensor makes computations intractable. To circumvent this issue, one approach known as MIRNN consists in limiting the type of interactions used by the model. Another is to leverage tensor decomposition to diminish the parameter count. In this work, we study the model resulting from parameterizing 2RNNs using the CP decomposition, which we call CPRNN. Intuitively, the rank of the decomposition should reduce expressivity. We analyze how rank and hidden size affect model capacity and show the relationships between RNNs, 2RNNs, MIRNNs, and CPRNNs based on these parameters. We support these results empirically with experiments on the Penn Treebank dataset which demonstrate that, with a fixed parameter budget, CPRNNs outperforms RNNs, 2RNNs, and MIRNNs with the right choice of rank and hidden size.",
    "authors": [
      {
        "affiliations": [],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/106509?format=json",
              "type": "profile"
            }
          ],
          "name": "Marawan Gamal"
        },
        "display_name": "Marawan Gamal"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Mila - Universit\u00e9 de Montr\u00e9al"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/125764?format=json",
              "type": "profile"
            }
          ],
          "name": "Maude Lizaire"
        },
        "display_name": "Maude Lizaire"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/99756?format=json",
              "type": "profile"
            }
          ],
          "name": "Guillaume Rabusseau"
        },
        "display_name": "Guillaume Rabusseau"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Universit\u00e9 de Montr\u00e9al"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/125766?format=json",
              "type": "profile"
            }
          ],
          "name": "Michael Rizvi-Martel"
        },
        "display_name": "Michael Rizvi-Martel"
      }
    ],
    "flags": [],
    "links": [
      {
        "link": "https://icml.cc/virtual/2024/poster/34560",
        "type": "abstract"
      },
      {
        "link": "https://proceedings.mlr.press/v235/lizaire24a.html",
        "type": "pdf"
      }
    ],
    "releases": [
      {
        "pages": null,
        "status": "Accept (Spotlight)",
        "venue": {
          "aliases": [],
          "date": "2024-07-23",
          "date_precision": 3,
          "links": [],
          "name": "ICML",
          "open": true,
          "peer_reviewed": true,
          "publisher": null,
          "series": "ICML",
          "type": "conference",
          "volume": null
        }
      }
    ],
    "title": "A Tensor Decomposition Perspective on Second-order RNNs",
    "topics": [
      {
        "name": "Deep Learning->Sequential Models, Time series"
      }
    ]
  },
  {
    "abstract": "The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry (*kinetic energy*), and the regularization of density paths (*potential energy*). These combinations yield different variational problems (*Lagrangians*), encompassing many variations of the optimal transport problem such as the Schr\u00f6dinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others. In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging. We propose a novel deep learning based framework approaching all of these problems from a unified perspective. Leveraging the dual formulation of the Lagrangians, our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings. We showcase the versatility of the proposed framework by outperforming previous approaches for the single-cell trajectory inference, where incorporating prior knowledge into the dynamics is crucial for correct predictions.",
    "authors": [
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Mila"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/92402?format=json",
              "type": "profile"
            }
          ],
          "name": "Alexander Tong"
        },
        "display_name": "Alexander Tong"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Universit\u00e9 de Montr\u00e9al, Mila"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/8271?format=json",
              "type": "profile"
            }
          ],
          "name": "Kirill Neklyudov"
        },
        "display_name": "Kirill Neklyudov"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "University of Texas, Austin"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/92899?format=json",
              "type": "profile"
            }
          ],
          "name": "qiang liu"
        },
        "display_name": "qiang liu"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "University of Toronto Vector Institute"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/97996?format=json",
              "type": "profile"
            }
          ],
          "name": "Lazar Atanackovic"
        },
        "display_name": "Lazar Atanackovic"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "University of Toronto"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/37429?format=json",
              "type": "profile"
            }
          ],
          "name": "Alireza Makhzani"
        },
        "display_name": "Alireza Makhzani"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Vector Institute"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/88580?format=json",
              "type": "profile"
            }
          ],
          "name": "Rob Brekelmans"
        },
        "display_name": "Rob Brekelmans"
      }
    ],
    "flags": [],
    "links": [
      {
        "link": "https://icml.cc/virtual/2024/poster/32732",
        "type": "abstract"
      },
      {
        "link": "https://proceedings.mlr.press/v235/neklyudov24a.html",
        "type": "pdf"
      }
    ],
    "releases": [
      {
        "pages": null,
        "status": "Accept (Poster)",
        "venue": {
          "aliases": [],
          "date": "2024-07-23",
          "date_precision": 3,
          "links": [],
          "name": "ICML",
          "open": true,
          "peer_reviewed": true,
          "publisher": null,
          "series": "ICML",
          "type": "conference",
          "volume": null
        }
      }
    ],
    "title": "A Computational Framework for Solving Wasserstein Lagrangian Flows",
    "topics": [
      {
        "name": "Probabilistic Methods"
      }
    ]
  },
  {
    "abstract": "This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possible.",
    "authors": [
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "DeepMind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/8841?format=json",
              "type": "profile"
            }
          ],
          "name": "Andre Barreto"
        },
        "display_name": "Andre Barreto"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Gatsby Unit and Google Deepmind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/8312?format=json",
              "type": "profile"
            }
          ],
          "name": "Arthur Gretton"
        },
        "display_name": "Arthur Gretton"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Google DeepMind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/15946?format=json",
              "type": "profile"
            }
          ],
          "name": "Yunhao Tang"
        },
        "display_name": "Yunhao Tang"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Google DeepMind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/23745?format=json",
              "type": "profile"
            }
          ],
          "name": "Mark Rowland"
        },
        "display_name": "Mark Rowland"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Google DeepMind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/7528?format=json",
              "type": "profile"
            }
          ],
          "name": "Marc Bellemare"
        },
        "display_name": "Marc Bellemare"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Google DeepMind"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/8541?format=json",
              "type": "profile"
            }
          ],
          "name": "Will Dabney"
        },
        "display_name": "Will Dabney"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "McGill University, Mila"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/72783?format=json",
              "type": "profile"
            }
          ],
          "name": "Harley Wiltzer"
        },
        "display_name": "Harley Wiltzer"
      },
      {
        "affiliations": [
          {
            "aliases": [],
            "category": "unknown",
            "name": "Mila / McGill"
          }
        ],
        "author": {
          "aliases": [],
          "links": [
            {
              "link": "http://icml.cc/api/miniconf/users/121983?format=json",
              "type": "profile"
            }
          ],
          "name": "Jesse Farebrother"
        },
        "display_name": "Jesse Farebrother"
      }
    ],
    "flags": [],
    "links": [
      {
        "link": "https://icml.cc/virtual/2024/poster/32627",
        "type": "abstract"
      },
      {
        "link": "https://proceedings.mlr.press/v235/wiltzer24a.html",
        "type": "pdf"
      }
    ],
    "releases": [
      {
        "pages": null,
        "status": "Accept (Spotlight)",
        "venue": {
          "aliases": [],
          "date": "2024-07-23",
          "date_precision": 3,
          "links": [],
          "name": "ICML",
          "open": true,
          "peer_reviewed": true,
          "publisher": null,
          "series": "ICML",
          "type": "conference",
          "volume": null
        }
      }
    ],
    "title": "A Distributional Analogue to the Successor Representation",
    "topics": [
      {
        "name": "Reinforcement Learning->Everything Else"
      }
    ]
  }
]